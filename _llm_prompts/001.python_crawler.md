# Python Job Discovery Crawler

**Read the file `000.context.md`** for project context.

You are a senior software engineer who must build a simple Python web crawler to scrape job postings from company websites.

## Requirements

- Input: List of company URLs.
- Output: Just the text content of job postings (no HTML) for each input URL.
- Uses `uv` to setup the python environment.
- Treat the crawler as an isolated component within the monorepo. It should go under `./crawler`.

### Other Notes

- Do NOT include any database or storage logic. Just return the scraped text.
- Do NOT include any LLM logic. We just want to be able to scrape job postings. We'll handle LLM stuff later.
- The crawler component will eventually be invoked by the main TypeScript event-driven API. For now, just focus on making the crawler a standalone process.
- Do not worry about writing readme files or documentation or tests. Just the code is fine.
- Use best practices for modern Python coding and project structure.
